# Требования к частям системы (Subsystem Requirements)

## 1. Мобильный клиент iOS (SwiftUI) — `src/app/mad_application`

### 1.1. Presentation слой (UI/UX)

- UI‑1: Навигация должна быть предсказуемой (Tab/Stack), глубина сценариев ограничена.
- UI‑2: Основные экраны должны поддерживать состояние: loading/empty/content/error.
- UI‑3: Для ошибок сети — отдельное «человеческое» сообщение и действие (Retry).
- UI‑4: Доступность: VoiceOver labels для интерактивных элементов, Dynamic Type, контраст.
- UI‑5: Экран подключения должен поддерживать: выбор профиля (LAN/VPN), проверку доступности, отображение статуса домашнего ПК.
- UI‑6: Экран чата должен поддерживать: streaming ответа, stop/cancel, повтор отправки, индикацию «модель думает».
- UI‑7: Экран настроек должен позволять выбрать модель по умолчанию и базовые параметры генерации (например, temperature).

### 1.2. Domain слой (Use Cases)

- D‑1: Все бизнес‑операции должны быть оформлены как use‑cases с явными входами/выходами.
- D‑2: Должны быть определены доменные модели без зависимости от UI/Network.
- D‑3: Ошибки должны быть типизированы (network/auth/validation/unknown) для UX‑обработки.
- D‑4: Use‑case «SendPrompt» должен поддерживать streaming и cancel.
- D‑5: Use‑case «ListModels» должен получать список моделей Ollama (через gateway или напрямую).
- D‑6: Use‑case «TestConnection/HealthCheck» должен выполняться при настройке профиля подключения.

### 1.3. Data слой (Repositories)

- R‑1: Репозитории должны скрывать источник данных (remote/local/cache).
- R‑2: Репозиторий должен обеспечивать политику кэша (stale‑while‑revalidate или explicit refresh).
- R‑3: Должна быть стратегия ретраев и таймаутов для сетевых запросов.
- R‑4: История диалогов должна храниться локально с настройкой «хранить/не хранить», и поддерживать очистку.

### 1.4. Networking

- N‑1: Все запросы выполняются через единый клиент (URLSession), с логированием без PII.
- N‑2: Поддерживаются стандартные коды ошибок (401/403/404/429/5xx) и маппинг в доменные ошибки.
- N‑3: Конфигурация окружений (dev/stage/prod) задается через build settings или конфиг.
- N‑4: Для streaming ответов должен использоваться поддерживаемый транспорт (SSE/HTTP chunked/WebSocket — выбрать при проектировании gateway).
- N‑5: Должны быть ограничения: максимальный размер промпта/контекста на клиенте, чтобы избежать OOM/тормозов.

### 1.5. Persistence (локальные данные)

- P‑1: Токены/секреты — только Keychain.
- P‑2: Кэш данных — в CoreData/SQLite/FileCache (выбрать), с ограничением размера и TTL.
- P‑3: При очистке данных (logout) локальный кэш пользователя должен быть удален.
- P‑4: Профили подключения (адреса) должны храниться локально; секреты (ключи/токены) — раздельно в Keychain.

### 1.6. Observability в клиенте

- O‑1: Клиент должен отправлять crash‑события в выбранный инструмент (Crashlytics/Sentry).
- O‑2: Клиент должен логировать ключевые события UX (начало/успех/ошибка сценария) в аналитику.
- O‑3: Клиент должен измерять время: старт приложения, загрузка экрана/списка (включая network).
- O‑4: Клиент должен измерять метрики LLM: TTFT (time-to-first-token), время полного ответа, cancel rate, retry rate.

### 1.7. Обратная связь в клиенте

- F‑1: Кнопка «Обратная связь» доступна из Settings/Help.
- F‑2: Периодический NPS/CSI prompt показывается после завершения ключевого use‑case (rate‑limit).
- F‑3: Пользователь может приложить комментарий и (опционально) скриншот/логи без PII.

## 2. Backend API (Gateway/монолит или микросервисы)

### 2.1. Home Gateway / BFF (рекомендуется на домашнем ПК)

- BFF‑1: Единая точка входа для мобильного клиента к домашнему ПК; проксирует запросы к Ollama.
- BFF‑2: Аутентификация клиента (token/pairing/mTLS) обязательна; анонимный доступ запрещен.
- BFF‑3: Rate limiting и защита от злоупотреблений (429), лимиты промпта/частоты запросов.
- BFF‑4: Логирование запросов и корреляция (request_id/trace_id), без сохранения промптов по умолчанию.
- BFF‑5: Поддержка streaming проксирования (SSE/WebSocket) без буферизации всего ответа.

### 2.2. Auth (в составе gateway или отдельный сервис)

- AUTH‑1: Pairing устройства (одноразовый код/QR) и выпуск ключа/токена для клиента.
- AUTH‑2: Ротация/отзыв токенов и управление списком привязанных устройств.

### 2.3. Ollama service (уже установлен на домашнем ПК)

- OLL‑1: Предоставляет endpoint для генерации текста и список доступных моделей.
- OLL‑2: Должен быть доступен только из доверенной сети/через gateway (не «голый» в интернет).

### 2.4. Data storage (опционально)

- DB‑1: При необходимости истории/настроек на сервере — хранить только метаданные и конфиги (по умолчанию без промптов).
- DB‑2: Если сохраняются диалоги — включить явное согласие пользователя и шифрование.

## 3. Система качества (Observability/Monitoring)

### 3.1. Метрики и мониторинг

- MON‑1: Backend должен экспортировать метрики в Prometheus (latency, RPS, error rate).
- MON‑2: Дашборды Grafana должны покрывать SLI/SLO (аптайм, p95 latency, error budget).
- MON‑3: Альтернатива/дополнение: Zabbix для инфраструктуры (CPU/RAM/диск/сеть).

### 3.2. Логи и трассировки

- LOG‑1: Централизованный сбор логов (например, Loki/ELK) с корреляцией по trace_id.
- TRACE‑1: Распределенные трассы (OpenTelemetry) для выявления узких мест.

## 4. Аналитика продукта

- ANA‑1: События фиксируются с версией приложения, платформой, экраном, исходом (success/fail).
- ANA‑2: Не хранить PII без необходимости; обеспечить согласие пользователя при сборе.
- ANA‑3: Метрики ретеншна/конверсии/времени сессии доступны в отчете.
- ANA‑4: Промпт/ответ не отправляются в аналитику по умолчанию; допускается только агрегированная телеметрия.

## 5. Сервис обратной связи

- FB‑1: Прием NPS/CSI ответов и текстовых сообщений.
- FB‑2: Хранение связки: версия приложения, устройство, OS, сценарий, timestamp.
- FB‑3: Маршрутизация в issue tracker (опционально) и SLA обработки.

## 6. VPS Edge Layer (public IP + AmneziaWG)

### 6.1. AmneziaWG (WireGuard server) на VPS

- VPS‑WG‑1: Сервер WireGuard должен принимать подключения только от доверенных peer’ов (домашний ПК).
- VPS‑WG‑2: Должны быть настроены firewall правила, запрещающие доступ к внутренним сервисам минуя WG интерфейс.
- VPS‑WG‑3: Должна быть обеспечена наблюдаемость туннеля: handshake age/uptime/traffic.

### 6.2. Reverse proxy на VPS (Caddy/Nginx)

- VPS‑RP‑1: Reverse proxy должен завершать TLS и проксировать запросы к домашнему gateway по WG интерфейсу.
- VPS‑RP‑2: Должны быть лимиты: request size, rate limiting (или проброс к gateway, но не «безлимит» на публичном IP).
- VPS‑RP‑3: Должны быть базовые заголовки безопасности и корректная обработка streaming (без полного буфера).
